<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Introduction to SeBR ‚Ä¢ SeBR</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to SeBR">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">SeBR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item"><a class="nav-link" href="../articles/SeBR.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/drkowal/SeBR/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Introduction to SeBR</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/drkowal/SeBR/blob/master/vignettes/SeBR.Rmd" class="external-link"><code>vignettes/SeBR.Rmd</code></a></small>
      <div class="d-none name"><code>SeBR.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="background-semiparametric-regression-via-data-transformations">Background: semiparametric regression via data transformations<a class="anchor" aria-label="anchor" href="#background-semiparametric-regression-via-data-transformations"></a>
</h2>
<p>Data transformations are a useful companion for parametric regression
models. A well-chosen or learned transformation can greatly enhance the
applicability of a given model, especially for data with irregular
marginal features (e.g., multimodality, skewness) or various data
domains (e.g., real-valued, positive, or compactly-supported data).</p>
<p>We are interested in providing fully Bayesian inference for
<em>semiparametric regression models</em> that incorporate (1) an
unknown data transformation and (2) a useful parametric regression
model. For paired data
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><msubsup><mo stretchy="false" form="postfix">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup></mrow><annotation encoding="application/x-tex">\{x_i, y_i\}_{i=1}^n</annotation></semantics></math>
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>‚àà</mo><msup><mi>‚Ñù</mi><mi>p</mi></msup></mrow><annotation encoding="application/x-tex">x_i \in \mathbb{R}^p</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>‚àà</mo><mi>ùí¥</mi><mo>‚äÜ</mo><mi>‚Ñù</mi></mrow><annotation encoding="application/x-tex">y \in \mathcal{Y} \subseteq \mathbb{R}</annotation></semantics></math>,
consider the following class of models:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>z</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
g(y_i) = z_i
</annotation></semantics></math><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>=</mo><msub><mi>f</mi><mi>Œ∏</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>œÉ</mi><msub><mi>œµ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
z_i  = f_\theta(x_i) + \sigma \epsilon_i
</annotation></semantics></math> Here,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
is a (monotone increasing) data transformation to be learned,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mi>Œ∏</mi></msub><annotation encoding="application/x-tex">f_\theta</annotation></semantics></math>
is an unknown regression function parametrized by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>œµ</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\epsilon_i</annotation></semantics></math>
are independent errors. Location and scale restrictions (e.g.,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>Œ∏</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">f_\theta(0) = 0</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÉ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\sigma =1</annotation></semantics></math>)
are usually applied for identifiability.</p>
<p><strong>Examples.</strong> We focus on the following important
special cases:</p>
<ol style="list-style-type: decimal">
<li><p>The <strong>linear model</strong> is a natural starting point:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mi>‚Ä≤</mi><mi>Œ∏</mi><mo>+</mo><mi>œÉ</mi><msub><mi>œµ</mi><mi>i</mi></msub><mo>,</mo><mspace width="1.0em"></mspace><msub><mi>œµ</mi><mi>i</mi></msub><mover><mo>‚àº</mo><mrow><mi>i</mi><mi>i</mi><mi>d</mi></mrow></mover><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
z_i = x_i'\theta + \sigma\epsilon_i, \quad \epsilon_i \stackrel{iid}{\sim} N(0, 1)
</annotation></semantics></math> The transformation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
broadens the applicability of this useful class of models, including for
positive or compactly-supported data (see below).</p></li>
<li><p>The <strong>quantile regression model</strong> replaces the
Gaussian assumption in the linear model with an <em>asymmetric
Laplace</em> distribution (ALD)
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mi>‚Ä≤</mi><mi>Œ∏</mi><mo>+</mo><mi>œÉ</mi><msub><mi>œµ</mi><mi>i</mi></msub><mo>,</mo><mspace width="1.0em"></mspace><msub><mi>œµ</mi><mi>i</mi></msub><mover><mo>‚àº</mo><mrow><mi>i</mi><mi>i</mi><mi>d</mi></mrow></mover><mi>A</mi><mi>L</mi><mi>D</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œÑ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
z_i = x_i'\theta + \sigma\epsilon_i, \quad \epsilon_i \stackrel{iid}{\sim} ALD(\tau)
</annotation></semantics></math> to target the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œÑ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>th
quantile of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>
at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>,
or equivalently, the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>g</mi><mrow><mo>‚àí</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>œÑ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">g^{-1}(\tau)</annotation></semantics></math>th
quantile of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>.
The ALD is quite often a very poor model for real data, especially when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œÑ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>
is near zero or one. The transformation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
offers a pathway to significantly improve the model adequacy, while
still targeting the desired quantile of the data.</p></li>
<li><p>The <strong>Gaussian process (GP) model</strong> generalizes the
linear model to include a nonparametric regression function,
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>=</mo><msub><mi>f</mi><mi>Œ∏</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>œÉ</mi><msub><mi>œµ</mi><mi>i</mi></msub><mo>,</mo><mspace width="1.0em"></mspace><msub><mi>œµ</mi><mi>i</mi></msub><mover><mo>‚àº</mo><mrow><mi>i</mi><mi>i</mi><mi>d</mi></mrow></mover><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
z_i = f_\theta(x_i) + \sigma \epsilon_i, \quad  \epsilon_i \stackrel{iid}{\sim} N(0, 1)
</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mi>Œ∏</mi></msub><annotation encoding="application/x-tex">f_\theta</annotation></semantics></math>
is a GP and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
parameterizes the mean and covariance functions. Although GPs offer
substantial flexibility for the regression function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mi>Œ∏</mi></msub><annotation encoding="application/x-tex">f_\theta</annotation></semantics></math>,
the default approach (without a transformation) may be inadequate when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
has irregular marginal features or a restricted domain (e.g., positive
or compact).</p></li>
</ol>
<p><strong>Challenges:</strong> The goal is to provide fully Bayesian
posterior inference for the unknowns
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>g</mi><mo>,</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(g, \theta)</annotation></semantics></math>
and posterior predictive inference for future/unobserved data
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>y</mi><mo accent="true">ÃÉ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\tilde y(x)</annotation></semantics></math>.
We prefer a model and algorithm that offer both (i) flexible modeling of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
and (ii) efficient posterior and predictive computations.</p>
<p><strong>Innovations:</strong> Our approach (<a href="https://doi.org/10.1080/01621459.2024.2395586" class="external-link uri">https://doi.org/10.1080/01621459.2024.2395586</a>) specifies
a <em>nonparametric</em> model for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>,
yet also provides <em>Monte Carlo</em> (not MCMC) sampling for the
posterior and predictive distributions. As a result, we control the
approximation accuracy via the number of simulations, but do
<em>not</em> require the lengthy runs, burn-in periods, convergence
diagnostics, or inefficiency factors that accompany MCMC. The Monte
Carlo sampling is typically quite fast.</p>
</div>
<div class="section level2">
<h2 id="using-sebr">Using <code>SeBR</code><a class="anchor" aria-label="anchor" href="#using-sebr"></a>
</h2>
<p>The <code>R</code> package <code>SeBR</code> is installed and loaded
as follows:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># install.packages("devtools")</span></span>
<span><span class="co"># devtools::install_github("drkowal/SeBR")</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/drkowal/SeBR" class="external-link">SeBR</a></span><span class="op">)</span> </span></code></pre></div>
<p>The main functions in <code>SeBR</code> are:</p>
<ul>
<li><p><code><a href="../reference/sblm.html">sblm()</a></code>: Monte Carlo sampling for posterior and
predictive inference with the <em>semiparametric Bayesian linear
model</em>;</p></li>
<li><p><code><a href="../reference/sbsm.html">sbsm()</a></code>: Monte Carlo sampling for posterior and
predictive inference with the <em>semiparametric Bayesian spline
model</em>, which replaces the linear model with a spline for nonlinear
modeling of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>‚àà</mo><mi>‚Ñù</mi></mrow><annotation encoding="application/x-tex">x \in \mathbb{R}</annotation></semantics></math>;</p></li>
<li><p><code><a href="../reference/sbqr.html">sbqr()</a></code>: blocked Gibbs sampling for posterior and
predictive inference with the <em>semiparametric Bayesian quantile
regression</em>; and</p></li>
<li><p><code><a href="../reference/sbgp.html">sbgp()</a></code>: Monte Carlo sampling for predictive
inference with the <em>semiparametric Bayesian Gaussian process
model</em>.</p></li>
</ul>
<p>Each function returns a point estimate of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
(<code>coefficients</code>), point predictions at some specified testing
points (<code>fitted.values</code>), posterior samples of the
transformation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
(<code>post_g</code>), and posterior predictive samples of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>y</mi><mo accent="true">ÃÉ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\tilde y(x)</annotation></semantics></math>
at the testing points (<code>post_ypred</code>), as well as other
function-specific quantities (e.g., posterior draws of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>,
<code>post_theta</code>). The calls <code><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef()</a></code> and
<code><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted()</a></code> extract the point estimates and point predictions,
respectively.</p>
<p><strong>Note:</strong> The package also includes Box-Cox variants of
these functions, i.e., restricting
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
to the (signed) Box-Cox parametric family
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo>;</mo><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo stretchy="false" form="prefix">{</mo><mtext mathvariant="normal">sign</mtext><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="postfix">|</mo><mi>t</mi><msup><mo stretchy="false" form="postfix">|</mo><mi>Œª</mi></msup><mo>‚àí</mo><mn>1</mn><mo stretchy="false" form="postfix">}</mo><mi>/</mi><mi>Œª</mi></mrow><annotation encoding="application/x-tex">g(t; \lambda) = \{\mbox{sign}(t) \vert t \vert^\lambda - 1\}/\lambda</annotation></semantics></math>
with known or unknown
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>.
The parametric transformation is less flexible, especially for irregular
marginals or restricted domains, and requires MCMC sampling. These
functions (e.g., <code><a href="../reference/blm_bc.html">blm_bc()</a></code>, etc.) are primarily for
benchmarking.</p>
</div>
<div class="section level2">
<h2 id="semiparametric-bayesian-linear-models-with-sblm">Semiparametric Bayesian linear models with <code>sblm</code><a class="anchor" aria-label="anchor" href="#semiparametric-bayesian-linear-models-with-sblm"></a>
</h2>
<p>We simulate data from a transformed linear model:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span> <span class="co"># for reproducibility</span></span>
<span></span>
<span><span class="co"># Simulate data from a transformed linear model:</span></span>
<span><span class="va">dat</span> <span class="op">=</span> <span class="fu"><a href="../reference/simulate_tlm.html">simulate_tlm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">200</span>,  <span class="co"># number of observations</span></span>
<span>                   p <span class="op">=</span> <span class="fl">10</span>,   <span class="co"># number of covariates </span></span>
<span>                   g_type <span class="op">=</span> <span class="st">'step'</span> <span class="co"># type of transformation (here, positive data)</span></span>
<span>                   <span class="op">)</span></span>
<span><span class="co"># Training data:</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">y</span>; <span class="va">X</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">X</span> </span>
<span></span>
<span><span class="co"># Testing data:</span></span>
<span><span class="va">y_test</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">y_test</span>; <span class="va">X_test</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">X_test</span> </span></code></pre></div>
<p><code><a href="../reference/sblm.html">sblm()</a></code> quickly produces Monte Carlo samples of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo>,</mo><mi>g</mi><mo>,</mo><mover><mi>y</mi><mo accent="true">ÃÉ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mrow><mi>t</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\theta, g, \tilde y(X_{test}))</annotation></semantics></math>
under the semiparametric Bayesian linear model:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fit the semiparametric Bayesian linear model:</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/sblm.html">sblm</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, </span>
<span>           X <span class="op">=</span> <span class="va">X</span>, </span>
<span>           X_test <span class="op">=</span> <span class="va">X_test</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "8 seconds remaining"</span></span>
<span><span class="co">#&gt; [1] "5 seconds remaining"</span></span>
<span><span class="co">#&gt; [1] "3 seconds remaining"</span></span>
<span><span class="co">#&gt; [1] "Total time:  8 seconds"</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span> <span class="co"># what is returned</span></span>
<span><span class="co">#&gt;  [1] "coefficients"  "fitted.values" "post_theta"    "post_ypred"   </span></span>
<span><span class="co">#&gt;  [5] "post_g"        "model"         "y"             "X"            </span></span>
<span><span class="co">#&gt;  [9] "X_test"        "psi"           "approx_g"      "sigma_epsilon"</span></span></code></pre></div>
<p>These are Monte Carlo (not MCMC) samples, so we do <em>not</em> need
to perform any MCMC diagnostics (e.g., verify convergence, inspect
autocorrelations, discard a burn-in, re-run multiple chains, etc.).</p>
<p>First, we check for model adequacy using posterior predictive
diagnostics. Specifically, we compute the empirical CDF on both
<code>y_test</code> (black) and on each simulated testing predictive
dataset from <code>post_ypred</code> (gray):</p>
<p><img src="SeBR_files/figure-html/ppd-1.png" width="576"></p>
<p>Despite the challenging features of this marginal distribution, the
proposed model appears to be adequate. Although the gray lines are not
clearly visible at zero or one, the posterior predictive distribution
does indeed match the support of the observed data.</p>
<p><strong>Remark:</strong> Posterior predictive diagnostics do not
require training/testing splits and are typically performed in-sample.
If <code>X_test</code> is left unspecified in <code>sblm</code>, then
the posterior predictive draws are given at <code>X</code> and can be
compared to <code>y</code>. The example above uses out-of-sample checks,
which are more rigorous but less common.</p>
<p>Next, we evaluate the predictive ability on the testing dataset by
computing and plotting the out-of-sample prediction intervals at
<code>X_test</code> and comparing them to <code>y_test</code>. There is
a built-in function for this:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Evaluate posterior predictive means and intervals on the testing data:</span></span>
<span><span class="fu"><a href="../reference/plot_pptest.html">plot_pptest</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_ypred</span>, </span>
<span>            <span class="va">y_test</span>, </span>
<span>            alpha_level <span class="op">=</span> <span class="fl">0.10</span><span class="op">)</span> <span class="co"># coverage should be &gt;= 90% </span></span></code></pre></div>
<p><img src="SeBR_files/figure-html/pi-1.png" width="576"></p>
<pre><code><span><span class="co">#&gt; [1] 0.93</span></span></code></pre>
<p>The out-of-sample predictive distributions are well-calibrated.</p>
<p>Finally, we summarize the posterior inference for the transformation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
and the regression coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
and compare to the ground truth values. First, we plot the posterior
draws of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
(gray), the posterior mean of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
(black), and the true transformation (triangles):
<img src="SeBR_files/figure-html/comp-1.png" width="576"></p>
<p>The posterior distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
accurately matches the true transformation.</p>
<p>Next, we compute point and interval summaries for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
and compare them to the ground truth:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Summarize the parameters (regression coefficients):</span></span>
<span></span>
<span><span class="co"># Posterior means:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="co">#&gt;  [1]  0.07314744  0.47686070  0.44598444  0.48627809  0.34035855  0.39385554</span></span>
<span><span class="co">#&gt;  [7]  0.08038143  0.12864699 -0.04873447 -0.08244957  0.08042865</span></span>
<span></span>
<span><span class="co"># Check: correlation with true coefficients</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">cor</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">beta_true</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="co"># excluding the intercept</span></span>
<span><span class="co">#&gt; [1] 0.9435131</span></span>
<span></span>
<span><span class="co"># 95% credible intervals:</span></span>
<span><span class="va">theta_ci</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_theta</span>, <span class="fl">2</span>, <span class="va">quantile</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">.025</span>, <span class="fl">0.975</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Check: agreement on nonzero coefficients?</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">theta_ci</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span> <span class="op">&gt;=</span> <span class="fl">0</span> <span class="op">|</span> <span class="va">theta_ci</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span> <span class="op">&lt;=</span><span class="fl">0</span><span class="op">)</span> <span class="co"># 95% CI excludes zero</span></span>
<span><span class="co">#&gt; [1] 2 3 4 5 6</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">beta_true</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span> <span class="co"># truly nonzero</span></span>
<span><span class="co">#&gt; [1] 2 3 4 5 6</span></span></code></pre></div>
<p>The point estimates of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
closely track the ground truth, and inference based on the 95% credible
intervals correctly selects the truly nonzero regression
coefficients.</p>
<p><strong>Remark:</strong> The location-scale of the data-generating
process and the model may not match exactly. Thus, we use correlations
to compare the regression coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
(while omitting the intercept) and apply location-scale shifts of the
transformations
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
to ensure comparability. This is only a byproduct of the simulated data
setting and does not matter for real data analysis (or for variable
selection).</p>
<p><strong>Note:</strong> Try repeating this exercise with
<code><a href="../reference/blm_bc.html">blm_bc()</a></code> in place of <code><a href="../reference/sblm.html">sblm()</a></code>. The Box-Cox
transformation cannot recover the transformation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
or the coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
accurately, the model diagnostics are alarming, and the predictions
deteriorate substantially.</p>
</div>
<div class="section level2">
<h2 id="semiparametric-bayesian-quantile-regression-with-sbqr">Semiparametric Bayesian quantile regression with
<code>sbqr</code><a class="anchor" aria-label="anchor" href="#semiparametric-bayesian-quantile-regression-with-sbqr"></a>
</h2>
<p>We now consider Bayesian quantile regression, which specifies a
linear model with ALD errors. First, we simulate data from a
heteroskedastic linear model. Heteroskedasticity often produces
conclusions that differ from traditional mean regression. Here, we do
<em>not</em> include a transformation, so the data-generating process
does not implicitly favor our approach over traditional Bayesian
quantile regression (i.e., with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>t</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>t</mi></mrow><annotation encoding="application/x-tex">g(t) = t</annotation></semantics></math>
the identity).</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Simulate data from a heteroskedastic linear model (no transformation):</span></span>
<span><span class="va">dat</span> <span class="op">=</span> <span class="fu"><a href="../reference/simulate_tlm.html">simulate_tlm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">200</span>,  <span class="co"># number of observations</span></span>
<span>                   p <span class="op">=</span> <span class="fl">10</span>,   <span class="co"># number of covariates </span></span>
<span>                   g_type <span class="op">=</span> <span class="st">'box-cox'</span>, lambda <span class="op">=</span> <span class="fl">1</span>, <span class="co"># no transformation</span></span>
<span>                   heterosked <span class="op">=</span> <span class="cn">TRUE</span> <span class="co"># heteroskedastic errors</span></span>
<span>                   <span class="op">)</span></span>
<span><span class="co"># Training data:</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">y</span>; <span class="va">X</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">X</span> </span>
<span></span>
<span><span class="co"># Testing data:</span></span>
<span><span class="va">y_test</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">y_test</span>; <span class="va">X_test</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">X_test</span> </span></code></pre></div>
<p>Next, we load in two packages that we‚Äôll need:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://www.r-project.org" class="external-link">quantreg</a></span><span class="op">)</span> <span class="co"># traditional QR for initialization</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">statmod</span><span class="op">)</span> <span class="co"># for rinvgauss sampling</span></span></code></pre></div>
<p>Now, we fit two Bayesian quantile regression models: the traditional
version without a transformation (<code><a href="../reference/bqr.html">bqr()</a></code>) and the proposed
alternative (<code><a href="../reference/sbqr.html">sbqr()</a></code>). We target the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÑ</mi><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">\tau = 0.05</annotation></semantics></math>
quantile.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Quantile to target:</span></span>
<span><span class="va">tau</span> <span class="op">=</span> <span class="fl">0.05</span></span>
<span></span>
<span><span class="co"># (Traditional) Bayesian quantile regression:</span></span>
<span><span class="va">fit_bqr</span> <span class="op">=</span> <span class="fu"><a href="../reference/bqr.html">bqr</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, </span>
<span>           X <span class="op">=</span> <span class="va">X</span>, </span>
<span>           tau <span class="op">=</span> <span class="va">tau</span>, </span>
<span>           X_test <span class="op">=</span> <span class="va">X_test</span>,</span>
<span>           verbose <span class="op">=</span> <span class="cn">FALSE</span>  <span class="co"># omit printout</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Semiparametric Bayesian quantile regression:</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/sbqr.html">sbqr</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, </span>
<span>           X <span class="op">=</span> <span class="va">X</span>, </span>
<span>           tau <span class="op">=</span> <span class="va">tau</span>, </span>
<span>           X_test <span class="op">=</span> <span class="va">X_test</span>,</span>
<span>           verbose <span class="op">=</span> <span class="cn">FALSE</span> <span class="co"># omit printout</span></span>
<span><span class="op">)</span></span>
<span>      </span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span> <span class="co"># what is returned</span></span>
<span><span class="co">#&gt;  [1] "coefficients"  "fitted.values" "post_theta"    "post_ypred"   </span></span>
<span><span class="co">#&gt;  [5] "post_qtau"     "post_g"        "model"         "y"            </span></span>
<span><span class="co">#&gt;  [9] "X"             "X_test"        "psi"           "approx_g"     </span></span>
<span><span class="co">#&gt; [13] "tau"</span></span></code></pre></div>
<p>For both model fits, we evaluate the same posterior predictive
diagnostics as before. Specifically, we compute the empirical CDF on
both <code>y_test</code> (black) and on each simulated testing
predictive dataset from <code>post_ypred</code> for <code>sbqr</code>
(gray) and <code>bqr</code> (red):
<img src="SeBR_files/figure-html/ppd-bqr-1.png" width="576"></p>
<p>Without the transformation, the Bayesian quantile regression model is
<em>not</em> a good model for the data. The learned transformation
completely resolves this model inadequacy‚Äîeven though there was no
transformation present in the data-generating process.</p>
<p>Finally, we can asses the quantile estimates on the testing data.
First, consider <code>bqr</code>:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Quantile point estimates:</span></span>
<span><span class="va">q_hat_bqr</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit_bqr</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># Empirical quantiles on testing data:</span></span>
<span><span class="op">(</span><span class="va">emp_quant_bqr</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">q_hat_bqr</span> <span class="op">&gt;=</span> <span class="va">y_test</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.026</span></span>
<span></span>
<span><span class="co"># Evaluate posterior predictive means and intervals on the testing data:</span></span>
<span><span class="op">(</span><span class="va">emp_cov_bqr</span> <span class="op">=</span> <span class="fu"><a href="../reference/plot_pptest.html">plot_pptest</a></span><span class="op">(</span><span class="va">fit_bqr</span><span class="op">$</span><span class="va">post_ypred</span>, </span>
<span>                           <span class="va">y_test</span>, </span>
<span>                           alpha_level <span class="op">=</span> <span class="fl">0.10</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="SeBR_files/figure-html/bqr-test-1.png" width="576"></p>
<pre><code><span><span class="co">#&gt; [1] 0.98</span></span></code></pre>
<p>Recall that these are <em>quantile</em> regression models at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œÑ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>,
so we expect them to be asymmetric about <code>y_test</code>.</p>
<p>The out-of-sample empirical quantile is 0.026 (the target is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÑ</mi><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">\tau = 0.05</annotation></semantics></math>)
and the 90% prediction interval coverage is 0.98.</p>
<p>Repeat this evaluation for <code>sbqr</code>:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Quantile point estimates:</span></span>
<span><span class="va">q_hat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># Empirical quantiles on testing data:</span></span>
<span><span class="op">(</span><span class="va">emp_quant_sbqr</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">q_hat</span> <span class="op">&gt;=</span> <span class="va">y_test</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.034</span></span>
<span></span>
<span><span class="co"># Evaluate posterior predictive means and intervals on the testing data:</span></span>
<span><span class="op">(</span><span class="va">emp_cov_sbqr</span> <span class="op">=</span> <span class="fu"><a href="../reference/plot_pptest.html">plot_pptest</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_ypred</span>, </span>
<span>                            <span class="va">y_test</span>, </span>
<span>                            alpha_level <span class="op">=</span> <span class="fl">0.10</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="SeBR_files/figure-html/sbqr-test-1.png" width="576"></p>
<pre><code><span><span class="co">#&gt; [1] 0.97</span></span></code></pre>
<p>Now the out-of-sample empirical quantile is 0.034 and the 90%
prediction interval coverage is 0.97. <code>sbqr</code> is better
calibrated to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œÑ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>,
while both methods are slightly overconservative in the prediction
interval coverage. However, <code>sbqr</code> produce significantly
smaller prediction intervals while maintaining this conservative
coverage, and thus provides more powerful and precise inference.</p>
<p><strong>Remark:</strong> point and interval estimates for the
quantile regression coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
may be computed exactly as in the <code><a href="../reference/sblm.html">sblm()</a></code> example.</p>
<p><strong>Note:</strong> try this again for other quantiles, such as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÑ</mi><mo>‚àà</mo><mo stretchy="false" form="prefix">{</mo><mn>0.25</mn><mo>,</mo><mn>0.5</mn><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\tau \in\{0.25, 0.5\}</annotation></semantics></math>.
As
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œÑ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>
approaches 0.5 (i.e., median regression), the problem becomes easier and
the models are better calibrated.</p>
</div>
<div class="section level2">
<h2 id="semiparametric-bayesian-gaussian-processes-with-sbgp">Semiparametric Bayesian Gaussian processes with
<code>sbgp</code><a class="anchor" aria-label="anchor" href="#semiparametric-bayesian-gaussian-processes-with-sbgp"></a>
</h2>
<p>Consider a challenging scenario with (i) a nonlinear regression
function of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>‚àà</mo><mi>‚Ñù</mi></mrow><annotation encoding="application/x-tex">x \in \mathbb{R}</annotation></semantics></math>
and (ii) Beta marginals, so the support is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùí¥</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{Y} = [0,1]</annotation></semantics></math>.
Simulate data accordingly:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Training data:</span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">200</span> <span class="co"># sample size</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length <span class="op">=</span> <span class="va">n</span><span class="op">)</span> <span class="co"># observation points</span></span>
<span></span>
<span><span class="co"># Testing data:</span></span>
<span><span class="va">n_test</span> <span class="op">=</span> <span class="fl">1000</span> </span>
<span><span class="va">x_test</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length <span class="op">=</span> <span class="va">n_test</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># True inverse transformation:</span></span>
<span><span class="va">g_inv_true</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">z</span><span class="op">)</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html" class="external-link">qbeta</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">pnorm</a></span><span class="op">(</span><span class="va">z</span><span class="op">)</span>, </span>
<span>        shape1 <span class="op">=</span> <span class="fl">0.5</span>, </span>
<span>        shape2 <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span> <span class="co"># approx Beta(0.5, 0.1) marginals</span></span>
<span></span>
<span><span class="co"># Training observations:</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="fu">g_inv_true</span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Trig.html" class="external-link">sin</a></span><span class="op">(</span><span class="fl">2</span><span class="op">*</span><span class="va">pi</span><span class="op">*</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Trig.html" class="external-link">sin</a></span><span class="op">(</span><span class="fl">4</span><span class="op">*</span><span class="va">pi</span><span class="op">*</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="fl">.25</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span>             <span class="op">)</span> </span>
<span></span>
<span><span class="co"># Testing observations:</span></span>
<span><span class="va">y_test</span> <span class="op">=</span> <span class="fu">g_inv_true</span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Trig.html" class="external-link">sin</a></span><span class="op">(</span><span class="fl">2</span><span class="op">*</span><span class="va">pi</span><span class="op">*</span><span class="va">x_test</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Trig.html" class="external-link">sin</a></span><span class="op">(</span><span class="fl">4</span><span class="op">*</span><span class="va">pi</span><span class="op">*</span><span class="va">x_test</span><span class="op">)</span> <span class="op">+</span> <span class="fl">.25</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span>             <span class="op">)</span> </span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="va">y_test</span>, </span>
<span>     xlab <span class="op">=</span> <span class="st">'x'</span>, ylab <span class="op">=</span> <span class="st">'y'</span>,</span>
<span>     main <span class="op">=</span> <span class="st">"Training (gray) and testing (black) data"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, type<span class="op">=</span><span class="st">'p'</span>, col<span class="op">=</span><span class="st">'gray'</span>, pch <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<p><img src="SeBR_files/figure-html/sim-gp-1.png" width="576"></p>
<p>To highlight the challenges here, we first consider a
Box-Cox-transformed GP. For this as well as the proposed model, we
require a package:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">GpGp</span><span class="op">)</span> <span class="co"># fast GP computing</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/dnychka/fieldsRPackage" class="external-link">fields</a></span><span class="op">)</span> <span class="co"># accompanies GpGp</span></span></code></pre></div>
<p>Now we fit the Box-Cox GP and evaluate the out-of-sample predictive
performance:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fit the Box-Cox Gaussian process model:</span></span>
<span><span class="va">fit_bc</span> <span class="op">=</span> <span class="fu"><a href="../reference/bgp_bc.html">bgp_bc</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, </span>
<span>           locs <span class="op">=</span> <span class="va">x</span>,</span>
<span>           locs_test <span class="op">=</span> <span class="va">x_test</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Initial GP fit..."</span></span>
<span><span class="co">#&gt; [1] "Updated GP fit..."</span></span>
<span></span>
<span><span class="co"># Fitted values on the testing data:</span></span>
<span><span class="va">y_hat_bc</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit_bc</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 90% prediction intervals on the testing data:</span></span>
<span><span class="va">pi_y_bc</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">fit_bc</span><span class="op">$</span><span class="va">post_ypred</span>, <span class="fl">2</span>, <span class="va">quantile</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.05</span>, <span class="fl">.95</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># Average PI width:</span></span>
<span><span class="op">(</span><span class="va">width_bc</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">pi_y_bc</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span> <span class="op">-</span> <span class="va">pi_y_bc</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.2668766</span></span>
<span></span>
<span><span class="co"># Empirical PI coverage:</span></span>
<span><span class="op">(</span><span class="va">emp_cov_bc</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">pi_y_bc</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span> <span class="op">&lt;=</span> <span class="va">y_test</span><span class="op">)</span><span class="op">*</span><span class="op">(</span><span class="va">pi_y_bc</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span> <span class="op">&gt;=</span> <span class="va">y_test</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.894</span></span>
<span></span>
<span><span class="co"># Plot these together with the actual testing points:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="va">y_test</span>, type<span class="op">=</span><span class="st">'n'</span>, </span>
<span>     ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html" class="external-link">range</a></span><span class="op">(</span><span class="va">pi_y_bc</span>, <span class="va">y_test</span><span class="op">)</span>, xlab <span class="op">=</span> <span class="st">'x'</span>, ylab <span class="op">=</span> <span class="st">'y'</span>, </span>
<span>     main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">'Fitted values and prediction intervals: \n Box-Cox Gaussian process'</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add the intervals:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/polygon.html" class="external-link">polygon</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="fu"><a href="https://rdrr.io/r/base/rev.html" class="external-link">rev</a></span><span class="op">(</span><span class="va">x_test</span><span class="op">)</span><span class="op">)</span>,</span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">pi_y_bc</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/base/rev.html" class="external-link">rev</a></span><span class="op">(</span><span class="va">pi_y_bc</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>,</span>
<span>        col<span class="op">=</span><span class="st">'gray'</span>, border<span class="op">=</span><span class="cn">NA</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="va">y_test</span>, type<span class="op">=</span><span class="st">'p'</span><span class="op">)</span> <span class="co"># actual values</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="va">y_hat_bc</span>, lwd <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="co"># fitted values</span></span></code></pre></div>
<p><img src="SeBR_files/figure-html/fit-bc-1.png" width="576"></p>
<p>The Box-Cox transformation adds some flexibility to the GP, but is
insufficient for these data. The prediction intervals are unnecessarily
wide and do not respect the support
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùí¥</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{Y} = [0,1]</annotation></semantics></math>,
while the estimated mean function does not fully capture the trend in
the data.</p>
<p>Now fit the semiparametric Bayesian GP model:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># library(GpGp) # loaded above</span></span>
<span></span>
<span><span class="co"># Fit the semiparametric Gaussian process model:</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/sbgp.html">sbgp</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, </span>
<span>           locs <span class="op">=</span> <span class="va">x</span>,</span>
<span>           locs_test <span class="op">=</span> <span class="va">x_test</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "Initial GP fit..."</span></span>
<span><span class="co">#&gt; [1] "Updated GP fit..."</span></span>
<span><span class="co">#&gt; [1] "Sampling..."</span></span>
<span><span class="co">#&gt; [1] "Done!"</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span> <span class="co"># what is returned</span></span>
<span><span class="co">#&gt;  [1] "coefficients"  "fitted.values" "fit_gp"        "post_ypred"   </span></span>
<span><span class="co">#&gt;  [5] "post_g"        "model"         "y"             "X"            </span></span>
<span><span class="co">#&gt;  [9] "approx_g"      "sigma_epsilon"</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span> <span class="co"># estimated regression coefficients (here, just an intercept)</span></span>
<span><span class="co">#&gt; [1] 0.02256587</span></span></code></pre></div>
<p>Evaluate the out-of-sample predictive performance on the testing
data:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fitted values on the testing data:</span></span>
<span><span class="va">y_hat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 90% prediction intervals on the testing data:</span></span>
<span><span class="va">pi_y</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_ypred</span>, <span class="fl">2</span>, <span class="va">quantile</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.05</span>, <span class="fl">.95</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> </span>
<span></span>
<span><span class="co"># Average PI width:</span></span>
<span><span class="op">(</span><span class="va">width</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">pi_y</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span> <span class="op">-</span> <span class="va">pi_y</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.2130283</span></span>
<span></span>
<span><span class="co"># Empirical PI coverage:</span></span>
<span><span class="op">(</span><span class="va">emp_cov</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">pi_y</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span> <span class="op">&lt;=</span> <span class="va">y_test</span><span class="op">)</span><span class="op">*</span><span class="op">(</span><span class="va">pi_y</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span> <span class="op">&gt;=</span> <span class="va">y_test</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.953</span></span>
<span></span>
<span><span class="co"># Plot these together with the actual testing points:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="va">y_test</span>, type<span class="op">=</span><span class="st">'n'</span>, </span>
<span>     ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html" class="external-link">range</a></span><span class="op">(</span><span class="va">pi_y</span>, <span class="va">y_test</span><span class="op">)</span>, xlab <span class="op">=</span> <span class="st">'x'</span>, ylab <span class="op">=</span> <span class="st">'y'</span>, </span>
<span>     main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">'Fitted values and prediction intervals: \n semiparametric Gaussian process'</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add the intervals:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/polygon.html" class="external-link">polygon</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="fu"><a href="https://rdrr.io/r/base/rev.html" class="external-link">rev</a></span><span class="op">(</span><span class="va">x_test</span><span class="op">)</span><span class="op">)</span>,</span>
<span>        <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">pi_y</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/base/rev.html" class="external-link">rev</a></span><span class="op">(</span><span class="va">pi_y</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>,</span>
<span>        col<span class="op">=</span><span class="st">'gray'</span>, border<span class="op">=</span><span class="cn">NA</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="va">y_test</span>, type<span class="op">=</span><span class="st">'p'</span><span class="op">)</span> <span class="co"># actual values</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="va">y_hat</span>, lwd <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="co"># fitted values</span></span></code></pre></div>
<p><img src="SeBR_files/figure-html/oos-gp-1.png" width="576"></p>
<p>Unlike the Box-Cox version, <code>sbgp</code> respects the support of
the data
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùí¥</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{Y} = [0,1]</annotation></semantics></math>,
captures the trend, and provides narrower intervals (average widths are
0.213 compared to 0.267) with better coverage (0.953 for
<code>sbgp</code> and 0.894 for Box-Cox).</p>
<p>Despite the significant complexities in the data, <code>sbgp</code>
performs quite well out-of-the-box:</p>
<ul>
<li><p>the nonlinearity is modeled adequately;</p></li>
<li><p>the support of the data is enforced automatically;</p></li>
<li><p>the out-of-sample prediction intervals are sharp and calibrated;
and</p></li>
<li><p>the computations are fast.</p></li>
</ul>
<p><strong>Note:</strong> <code>sbgp</code> also applies for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>‚àà</mo><msup><mi>‚Ñù</mi><mi>p</mi></msup></mrow><annotation encoding="application/x-tex">x \in \mathbb{R}^p</annotation></semantics></math>
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">p &gt;1</annotation></semantics></math>,
such as spatial or spatio-temporal data. Such cases may require more
careful consideration of the mean and covariance functions: the default
mean function is a linear regression with the intercept only, while the
default covariance function is an isotropic Matern function. However,
many other options are available (inherited from the <code>GpGp</code>
package).</p>
<div class="section level3">
<h3 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h3>
<p>Kowal, D. and Wu, B. (2024). Monte Carlo inference for semiparametric
Bayesian regression. <em>JASA</em>. <a href="https://doi.org/10.1080/01621459.2024.2395586" class="external-link uri">https://doi.org/10.1080/01621459.2024.2395586</a></p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Dan Kowal.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
