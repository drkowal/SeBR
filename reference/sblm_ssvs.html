<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Semiparametric Bayesian linear model with stochastic search variable selection — sblm_ssvs • SeBR</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Semiparametric Bayesian linear model with stochastic search variable selection — sblm_ssvs"><meta name="description" content="MCMC sampling for semiparametric Bayesian linear regression with
1) an unknown (nonparametric) transformation and 2) a sparsity prior on
the (possibly high-dimensional) regression coefficients. Here, unlike sblm,
Gibbs sampling is used for the variable inclusion indicator variables
gamma, referred to as stochastic search variable selection (SSVS).
All remaining terms–including the transformation g, the regression
coefficients theta, and any predictive draws–are drawn directly from
the joint posterior (predictive) distribution."><meta property="og:description" content="MCMC sampling for semiparametric Bayesian linear regression with
1) an unknown (nonparametric) transformation and 2) a sparsity prior on
the (possibly high-dimensional) regression coefficients. Here, unlike sblm,
Gibbs sampling is used for the variable inclusion indicator variables
gamma, referred to as stochastic search variable selection (SSVS).
All remaining terms–including the transformation g, the regression
coefficients theta, and any predictive draws–are drawn directly from
the joint posterior (predictive) distribution."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">SeBR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/SeBR.html">Get started</a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/drkowal/SeBR/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Semiparametric Bayesian linear model with stochastic search variable selection</h1>
      <small class="dont-index">Source: <a href="https://github.com/drkowal/SeBR/blob/master/R/source_varsel.R" class="external-link"><code>R/source_varsel.R</code></a></small>
      <div class="d-none name"><code>sblm_ssvs.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>MCMC sampling for semiparametric Bayesian linear regression with
1) an unknown (nonparametric) transformation and 2) a sparsity prior on
the (possibly high-dimensional) regression coefficients. Here, unlike <code><a href="sblm.html">sblm</a></code>,
Gibbs sampling is used for the variable inclusion indicator variables
<code>gamma</code>, referred to as stochastic search variable selection (SSVS).
All remaining terms–including the transformation <code>g</code>, the regression
coefficients <code>theta</code>, and any predictive draws–are drawn directly from
the joint posterior (predictive) distribution.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">sblm_ssvs</span><span class="op">(</span></span>
<span>  <span class="va">y</span>,</span>
<span>  <span class="va">X</span>,</span>
<span>  X_test <span class="op">=</span> <span class="va">X</span>,</span>
<span>  psi <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>,</span>
<span>  fixedX <span class="op">=</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">&gt;=</span> <span class="fl">500</span><span class="op">)</span>,</span>
<span>  approx_g <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  init_screen <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  a_pi <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  b_pi <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  nsave <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  nburn <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  ngrid <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-y">y<a class="anchor" aria-label="anchor" href="#arg-y"></a></dt>
<dd><p><code>n x 1</code> response vector</p></dd>


<dt id="arg-x">X<a class="anchor" aria-label="anchor" href="#arg-x"></a></dt>
<dd><p><code>n x p</code> matrix of predictors (no intercept)</p></dd>


<dt id="arg-x-test">X_test<a class="anchor" aria-label="anchor" href="#arg-x-test"></a></dt>
<dd><p><code>n_test x p</code> matrix of predictors for test data;
default is the observed covariates <code>X</code></p></dd>


<dt id="arg-psi">psi<a class="anchor" aria-label="anchor" href="#arg-psi"></a></dt>
<dd><p>prior variance (g-prior)</p></dd>


<dt id="arg-fixedx">fixedX<a class="anchor" aria-label="anchor" href="#arg-fixedx"></a></dt>
<dd><p>logical; if TRUE, treat the design as fixed (non-random) when sampling
the transformation; otherwise treat covariates as random with an unknown distribution</p></dd>


<dt id="arg-approx-g">approx_g<a class="anchor" aria-label="anchor" href="#arg-approx-g"></a></dt>
<dd><p>logical; if TRUE, apply large-sample
approximation for the transformation</p></dd>


<dt id="arg-init-screen">init_screen<a class="anchor" aria-label="anchor" href="#arg-init-screen"></a></dt>
<dd><p>for the initial approximation, number of covariates
to pre-screen (necessary when <code>p &gt; n</code>); if NULL, use <code>n/log(n)</code></p></dd>


<dt id="arg-a-pi">a_pi<a class="anchor" aria-label="anchor" href="#arg-a-pi"></a></dt>
<dd><p>shape1 parameter of the (Beta) prior inclusion probability</p></dd>


<dt id="arg-b-pi">b_pi<a class="anchor" aria-label="anchor" href="#arg-b-pi"></a></dt>
<dd><p>shape2 parameter of the (Beta) prior inclusion probability</p></dd>


<dt id="arg-nsave">nsave<a class="anchor" aria-label="anchor" href="#arg-nsave"></a></dt>
<dd><p>number of MCMC simulations to save</p></dd>


<dt id="arg-nburn">nburn<a class="anchor" aria-label="anchor" href="#arg-nburn"></a></dt>
<dd><p>number of MCMC iterations to discard</p></dd>


<dt id="arg-ngrid">ngrid<a class="anchor" aria-label="anchor" href="#arg-ngrid"></a></dt>
<dd><p>number of grid points for inverse approximations</p></dd>


<dt id="arg-verbose">verbose<a class="anchor" aria-label="anchor" href="#arg-verbose"></a></dt>
<dd><p>logical; if TRUE, print time remaining</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>a list with the following elements:</p><ul><li><p><code>coefficients</code> the posterior mean of the regression coefficients</p></li>
<li><p><code>fitted.values</code> the posterior predictive mean at the test points <code>X_test</code></p></li>
<li><p><code>selected</code>: the variables (columns of <code>X</code>) selected by the median probability model</p></li>
<li><p><code>pip</code>: (marginal) posterior inclusion probabilities for each variable</p></li>
<li><p><code>post_theta</code>: <code>nsave x p</code> samples from the posterior distribution
of the regression coefficients</p></li>
<li><p><code>post_gamma</code>: <code>nsave x p</code> samples from the posterior distribution
of the variable inclusion indicators</p></li>
<li><p><code>post_ypred</code>: <code>nsave x n_test</code> samples
from the posterior predictive distribution at test points <code>X_test</code></p></li>
<li><p><code>post_g</code>: <code>nsave</code> posterior samples of the transformation
evaluated at the unique <code>y</code> values</p></li>
<li><p><code>model</code>: the model fit (here, <code>sblm_ssvs</code>)</p></li>
</ul><p>as well as the arguments passed in.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>This function provides fully Bayesian inference for a
transformed linear model with sparse g-priors on the regression coefficients.
The transformation is modeled as unknown and learned jointly
with the regression coefficients (unless <code>approx_g</code> = TRUE, which then uses
a point approximation). This model applies for real-valued data, positive data, and
compactly-supported data (the support is automatically deduced from the observed <code>y</code> values).
By default, <code>fixedX</code> is set to <code>FALSE</code> for smaller datasets (<code>n &lt; 500</code>)
and <code>TRUE</code> for larger datasets.</p>
<p>The sparsity prior is especially useful for variable selection. Compared
to the horseshoe prior version (<code><a href="sblm_hs.html">sblm_hs</a></code>), the sparse g-prior
is advantageous because 1) it truly allows for sparse (i.e., exactly zero)
coefficients in the prior and posterior, 2) it incorporates covariate
dependencies via the g-prior structure, and 3) it tends to perform well
under both sparse and non-sparse regimes, while the horseshoe version only
performs well under sparse regimes. The disadvantage is that
SSVS does not scale nearly as well in <code>p</code>.</p>
<p>Following Scott and Berger (&lt;https://doi.org/10.1214/10-AOS792&gt;),
we include a <code>Beta(a_pi, b_pi)</code> prior on the prior inclusion probability. This term
is then sampled with the variable inclusion indicators <code>gamma</code> in a
Gibbs sampling block. All other terms are sampled using direct Monte Carlo
(not MCMC) sampling.</p>
<p>Alternatively, model probabilities can be computed directly
(by Monte Carlo, not MCMC/Gibbs sampling) using <code><a href="sblm_modelsel.html">sblm_modelsel</a></code>.</p>
    </div>
    <div class="section level2">
    <h2 id="note">Note<a class="anchor" aria-label="anchor" href="#note"></a></h2>
    <p>The location (intercept) and scale (<code>sigma_epsilon</code>) are
not identified, so any intercepts in <code>X</code> and <code>X_test</code> will
be removed. The model-fitting *does* include an internal location-scale
adjustment, but the function only outputs inferential summaries for the
identifiable parameters.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># \donttest{</span></span></span>
<span class="r-in"><span><span class="co"># Simulate data from a transformed (sparse) linear model:</span></span></span>
<span class="r-in"><span><span class="va">dat</span> <span class="op">=</span> <span class="fu"><a href="simulate_tlm.html">simulate_tlm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100</span>, p <span class="op">=</span> <span class="fl">15</span>, g_type <span class="op">=</span> <span class="st">'step'</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">y</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">y</span>; <span class="va">X</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">X</span> <span class="co"># training data</span></span></span>
<span class="r-in"><span><span class="va">y_test</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">y_test</span>; <span class="va">X_test</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">X_test</span> <span class="co"># testing data</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html" class="external-link">hist</a></span><span class="op">(</span><span class="va">y</span>, breaks <span class="op">=</span> <span class="fl">25</span><span class="op">)</span> <span class="co"># marginal distribution</span></span></span>
<span class="r-plt img"><img src="sblm_ssvs-1.png" alt="" width="700" height="433"></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Fit the semiparametric Bayesian linear model with sparsity priors:</span></span></span>
<span class="r-in"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu">sblm_ssvs</span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, X <span class="op">=</span> <span class="va">X</span>, X_test <span class="op">=</span> <span class="va">X_test</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "25 sec remaining"</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "15 sec remaining"</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "Total time: 48 seconds"</span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span> <span class="co"># what is returned</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [1] "coefficients"  "fitted.values" "selected"      "pip"          </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [5] "post_theta"    "post_gamma"    "post_ypred"    "post_g"       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [9] "model"         "y"             "X"             "X_test"       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [13] "psi"           "fixedX"        "approx_g"      "init_screen"  </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [17] "a_pi"          "b_pi"         </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Evaluate posterior predictive means and intervals on the testing data:</span></span></span>
<span class="r-in"><span><span class="fu"><a href="plot_pptest.html">plot_pptest</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_ypred</span>, <span class="va">y_test</span>,</span></span>
<span class="r-in"><span>            alpha_level <span class="op">=</span> <span class="fl">0.10</span><span class="op">)</span> <span class="co"># coverage should be about 90%</span></span></span>
<span class="r-plt img"><img src="sblm_ssvs-2.png" alt="" width="700" height="433"></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 0.97</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Check: correlation with true coefficients</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">cor</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">beta_true</span>, <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 0.9375642</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Selected coefficients under median probability model:</span></span></span>
<span class="r-in"><span><span class="va">fit</span><span class="op">$</span><span class="va">selected</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 1 2 3 4 5 6 7 8</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># True signals:</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">beta_true</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 1 2 3 4 5 6 7 8</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Summarize the transformation:</span></span></span>
<span class="r-in"><span><span class="va">y0</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unique.html" class="external-link">unique</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="co"># posterior draws of g are evaluated at the unique y observations</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">y0</span>, <span class="va">fit</span><span class="op">$</span><span class="va">post_g</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span>, type<span class="op">=</span><span class="st">'n'</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html" class="external-link">range</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_g</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>     xlab <span class="op">=</span> <span class="st">'y'</span>, ylab <span class="op">=</span> <span class="st">'g(y)'</span>, main <span class="op">=</span> <span class="st">"Posterior draws of the transformation"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">temp</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">sapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_g</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">s</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">y0</span>, <span class="va">fit</span><span class="op">$</span><span class="va">post_g</span><span class="op">[</span><span class="va">s</span>,<span class="op">]</span>, col<span class="op">=</span><span class="st">'gray'</span><span class="op">)</span><span class="op">)</span> <span class="co"># posterior draws</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">y0</span>, <span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">colMeans</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_g</span><span class="op">)</span>, lwd <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="co"># posterior mean</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">dat</span><span class="op">$</span><span class="va">g_true</span>, type<span class="op">=</span><span class="st">'p'</span>, pch<span class="op">=</span><span class="fl">2</span><span class="op">)</span> <span class="co"># true transformation</span></span></span>
<span class="r-plt img"><img src="sblm_ssvs-3.png" alt="" width="700" height="433"></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Posterior predictive checks on testing data: empirical CDF</span></span></span>
<span class="r-in"><span><span class="va">y0</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unique.html" class="external-link">unique</a></span><span class="op">(</span><span class="va">y_test</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">y0</span>, <span class="va">y0</span>, type<span class="op">=</span><span class="st">'n'</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>     xlab<span class="op">=</span><span class="st">'y'</span>, ylab<span class="op">=</span><span class="st">'F_y'</span>, main <span class="op">=</span> <span class="st">'Posterior predictive ECDF'</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">temp</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">sapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_ypred</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">s</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">y0</span>, <span class="fu"><a href="https://rdrr.io/r/stats/ecdf.html" class="external-link">ecdf</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_ypred</span><span class="op">[</span><span class="va">s</span>,<span class="op">]</span><span class="op">)</span><span class="op">(</span><span class="va">y0</span><span class="op">)</span>, <span class="co"># ECDF of posterior predictive draws</span></span></span>
<span class="r-in"><span>        col<span class="op">=</span><span class="st">'gray'</span>, type <span class="op">=</span><span class="st">'s'</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">y0</span>, <span class="fu"><a href="https://rdrr.io/r/stats/ecdf.html" class="external-link">ecdf</a></span><span class="op">(</span><span class="va">y_test</span><span class="op">)</span><span class="op">(</span><span class="va">y0</span><span class="op">)</span>,  <span class="co"># ECDF of testing data</span></span></span>
<span class="r-in"><span>     col<span class="op">=</span><span class="st">'black'</span>, type <span class="op">=</span> <span class="st">'s'</span>, lwd <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="sblm_ssvs-4.png" alt="" width="700" height="433"></span>
<span class="r-in"><span><span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Dan Kowal.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

