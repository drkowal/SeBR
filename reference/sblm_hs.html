<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Semiparametric Bayesian linear model with horseshoe priors for high-dimensional data — sblm_hs • SeBR</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Semiparametric Bayesian linear model with horseshoe priors for high-dimensional data — sblm_hs"><meta name="description" content="MCMC sampling for semiparametric Bayesian linear regression with
1) an unknown (nonparametric) transformation and 2) a horseshoe prior for
the (possibly high-dimensional) regression coefficients. Here, unlike sblm,
Gibbs sampling is needed for the regression coefficients and the horseshoe
prior variance components. The transformation g is still sampled
unconditionally on the regression coefficients, which provides a more
efficient blocking within the Gibbs sampler."><meta property="og:description" content="MCMC sampling for semiparametric Bayesian linear regression with
1) an unknown (nonparametric) transformation and 2) a horseshoe prior for
the (possibly high-dimensional) regression coefficients. Here, unlike sblm,
Gibbs sampling is needed for the regression coefficients and the horseshoe
prior variance components. The transformation g is still sampled
unconditionally on the regression coefficients, which provides a more
efficient blocking within the Gibbs sampler."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">SeBR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/SeBR.html">Get started</a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/drkowal/SeBR/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Semiparametric Bayesian linear model with horseshoe priors for high-dimensional data</h1>
      <small class="dont-index">Source: <a href="https://github.com/drkowal/SeBR/blob/master/R/source_varsel.R" class="external-link"><code>R/source_varsel.R</code></a></small>
      <div class="d-none name"><code>sblm_hs.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>MCMC sampling for semiparametric Bayesian linear regression with
1) an unknown (nonparametric) transformation and 2) a horseshoe prior for
the (possibly high-dimensional) regression coefficients. Here, unlike <code><a href="sblm.html">sblm</a></code>,
Gibbs sampling is needed for the regression coefficients and the horseshoe
prior variance components. The transformation <code>g</code> is still sampled
unconditionally on the regression coefficients, which provides a more
efficient blocking within the Gibbs sampler.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">sblm_hs</span><span class="op">(</span></span>
<span>  <span class="va">y</span>,</span>
<span>  <span class="va">X</span>,</span>
<span>  X_test <span class="op">=</span> <span class="va">X</span>,</span>
<span>  fixedX <span class="op">=</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">&gt;=</span> <span class="fl">500</span><span class="op">)</span>,</span>
<span>  approx_g <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  init_screen <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  pilot_hs <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  nsave <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  nburn <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  ngrid <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-y">y<a class="anchor" aria-label="anchor" href="#arg-y"></a></dt>
<dd><p><code>n x 1</code> response vector</p></dd>


<dt id="arg-x">X<a class="anchor" aria-label="anchor" href="#arg-x"></a></dt>
<dd><p><code>n x p</code> matrix of predictors (no intercept)</p></dd>


<dt id="arg-x-test">X_test<a class="anchor" aria-label="anchor" href="#arg-x-test"></a></dt>
<dd><p><code>n_test x p</code> matrix of predictors for test data;
default is the observed covariates <code>X</code></p></dd>


<dt id="arg-fixedx">fixedX<a class="anchor" aria-label="anchor" href="#arg-fixedx"></a></dt>
<dd><p>logical; if TRUE, treat the design as fixed (non-random) when sampling
the transformation; otherwise treat covariates as random with an unknown distribution</p></dd>


<dt id="arg-approx-g">approx_g<a class="anchor" aria-label="anchor" href="#arg-approx-g"></a></dt>
<dd><p>logical; if TRUE, apply large-sample
approximation for the transformation</p></dd>


<dt id="arg-init-screen">init_screen<a class="anchor" aria-label="anchor" href="#arg-init-screen"></a></dt>
<dd><p>for the initial approximation, number of covariates
to pre-screen (necessary when <code>p &gt; n</code>); if NULL, use <code>n/log(n)</code></p></dd>


<dt id="arg-pilot-hs">pilot_hs<a class="anchor" aria-label="anchor" href="#arg-pilot-hs"></a></dt>
<dd><p>logical; if TRUE, use a short pilot run with a horseshoe
prior to estimate the marginal CDF of the latent z (otherwise, use a sparse Laplace approximation)</p></dd>


<dt id="arg-nsave">nsave<a class="anchor" aria-label="anchor" href="#arg-nsave"></a></dt>
<dd><p>number of MCMC simulations to save</p></dd>


<dt id="arg-nburn">nburn<a class="anchor" aria-label="anchor" href="#arg-nburn"></a></dt>
<dd><p>number of MCMC iterations to discard</p></dd>


<dt id="arg-ngrid">ngrid<a class="anchor" aria-label="anchor" href="#arg-ngrid"></a></dt>
<dd><p>number of grid points for inverse approximations</p></dd>


<dt id="arg-verbose">verbose<a class="anchor" aria-label="anchor" href="#arg-verbose"></a></dt>
<dd><p>logical; if TRUE, print time remaining</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>a list with the following elements:</p><ul><li><p><code>coefficients</code> the posterior mean of the regression coefficients</p></li>
<li><p><code>fitted.values</code> the posterior predictive mean at the test points <code>X_test</code></p></li>
<li><p><code>post_theta</code>: <code>nsave x p</code> samples from the posterior distribution
of the regression coefficients</p></li>
<li><p><code>post_ypred</code>: <code>nsave x n_test</code> samples
from the posterior predictive distribution at test points <code>X_test</code></p></li>
<li><p><code>post_g</code>: <code>nsave</code> posterior samples of the transformation
evaluated at the unique <code>y</code> values</p></li>
<li><p><code>model</code>: the model fit (here, <code>sblm_hs</code>)</p></li>
</ul><p>as well as the arguments passed in.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>This function provides fully Bayesian inference for a
transformed linear model with horseshoe priors using efficiently-blocked Gibbs sampling.
The transformation is modeled as unknown and learned jointly
with the regression coefficients (unless <code>approx_g</code> = TRUE, which then uses
a point approximation). This model applies for real-valued data, positive data, and
compactly-supported data (the support is automatically deduced from the observed <code>y</code> values).</p>
<p>The horseshoe prior is especially useful for high-dimensional settings with
many (possibly correlated) covariates. Compared to sparse or spike-and-slab
alternatives (see <code><a href="sblm_ssvs.html">sblm_ssvs</a></code>), the horseshoe prior
delivers more scalable computing in <code>p</code>. This function
uses a fast Cholesky-forward/backward sampler when <code>p &lt; n</code>
and the Bhattacharya et al. (&lt;https://doi.org/10.1093/biomet/asw042&gt;) sampler
when <code>p &gt; n</code>. Thus, the sampler can scale linear in <code>n</code>
(for fixed/small <code>p</code>) or linear in <code>p</code> (for fixed/small <code>n</code>).
Empirically, the horseshoe prior performs best under sparse regimes,
i.e., when the number of true signals (nonzero regression coefficients)
is a small fraction of the total number of variables.</p>
<p>To learn the transformation, <code>SeBR</code> infers the marginal CDF
of the latent data model <code>Fz</code> by integrating over the covariates
<code>X</code> and the coefficients <code>theta</code>. When <code>fixedX = TRUE</code>, the
<code>X</code> averaging is empirical; otherwise it uses the Bayesian bootstrap (<code><a href="bb.html">bb</a></code>).
By default, <code>fixedX</code> is set to <code>FALSE</code> for smaller datasets (<code>n &lt; 500</code>)
and <code>TRUE</code> for larger datasets. When <code>pilot_hs = TRUE</code>,
the algorithm fits an initial linear regression model
with a horseshoe prior (<code><a href="blm_bc_hs.html">blm_bc_hs</a></code>) to transformed data
(under a preliminary point estimate of the transformation) and
uses that posterior distribution to integrate over <code>theta</code>.
Otherwise, this marginalization is done using a sparse Laplace approximation
for speed and simplicity.</p>
    </div>
    <div class="section level2">
    <h2 id="note">Note<a class="anchor" aria-label="anchor" href="#note"></a></h2>
    <p>The location (intercept) and scale (<code>sigma_epsilon</code>) are
not identified, so any intercepts in <code>X</code> and <code>X_test</code> will
be removed. The model-fitting *does* include an internal location-scale
adjustment, but the function only outputs inferential summaries for the
identifiable parameters.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># \donttest{</span></span></span>
<span class="r-in"><span><span class="co"># Simulate data from a transformed (sparse) linear model:</span></span></span>
<span class="r-in"><span><span class="va">dat</span> <span class="op">=</span> <span class="fu"><a href="simulate_tlm.html">simulate_tlm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100</span>, p <span class="op">=</span> <span class="fl">50</span>, g_type <span class="op">=</span> <span class="st">'step'</span>, prop_sig <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">y</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">y</span>; <span class="va">X</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">X</span> <span class="co"># training data</span></span></span>
<span class="r-in"><span><span class="va">y_test</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">y_test</span>; <span class="va">X_test</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">X_test</span> <span class="co"># testing data</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html" class="external-link">hist</a></span><span class="op">(</span><span class="va">y</span>, breaks <span class="op">=</span> <span class="fl">25</span><span class="op">)</span> <span class="co"># marginal distribution</span></span></span>
<span class="r-plt img"><img src="sblm_hs-1.png" alt="" width="700" height="433"></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Fit the semiparametric Bayesian linear model with a horseshoe prior:</span></span></span>
<span class="r-in"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu">sblm_hs</span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span>, X <span class="op">=</span> <span class="va">X</span>, X_test <span class="op">=</span> <span class="va">X_test</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "3 sec remaining"</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "3 sec remaining"</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "Total time: 8 seconds"</span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span> <span class="co"># what is returned</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [1] "coefficients"  "fitted.values" "post_theta"    "post_ypred"   </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [5] "post_g"        "post_sigma"    "model"         "y"            </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  [9] "X"             "X_test"        "fixedX"        "approx_g"     </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [13] "init_screen"   "pilot_hs"     </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Evaluate posterior predictive means and intervals on the testing data:</span></span></span>
<span class="r-in"><span><span class="fu"><a href="plot_pptest.html">plot_pptest</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_ypred</span>, <span class="va">y_test</span>,</span></span>
<span class="r-in"><span>            alpha_level <span class="op">=</span> <span class="fl">0.10</span><span class="op">)</span> <span class="co"># coverage should be about 90%</span></span></span>
<span class="r-plt img"><img src="sblm_hs-2.png" alt="" width="700" height="433"></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 0.873</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Check: correlation with true coefficients</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">cor</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">beta_true</span>, <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 0.9770368</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Compute 95% credible intervals for the coefficients:</span></span></span>
<span class="r-in"><span><span class="va">ci_theta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_theta</span>, <span class="fl">2</span>, <span class="va">quantile</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.05</span><span class="op">/</span><span class="fl">2</span>, <span class="fl">1</span> <span class="op">-</span> <span class="fl">0.05</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># True positive/negative rates for "selected" coefficients:</span></span></span>
<span class="r-in"><span><span class="va">selected</span> <span class="op">=</span> <span class="op">(</span><span class="op">(</span><span class="va">ci_theta</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span> <span class="op">&gt;</span><span class="fl">0</span> <span class="op">|</span> <span class="va">ci_theta</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span> <span class="op">&lt;</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="co"># intervals exclude zero</span></span></span>
<span class="r-in"><span><span class="va">sigs_true</span> <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">beta_true</span> <span class="op">!=</span> <span class="fl">0</span> <span class="co"># true signals</span></span></span>
<span class="r-in"><span><span class="op">(</span><span class="va">TPR</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">selected</span> <span class="op">&amp;</span> <span class="va">sigs_true</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">sigs_true</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 1</span>
<span class="r-in"><span><span class="op">(</span><span class="va">TNR</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="op">!</span><span class="va">selected</span> <span class="op">&amp;</span> <span class="op">!</span><span class="va">sigs_true</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="op">!</span><span class="va">sigs_true</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 1</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Summarize the transformation:</span></span></span>
<span class="r-in"><span><span class="va">y0</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unique.html" class="external-link">unique</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="co"># posterior draws of g are evaluated at the unique y observations</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">y0</span>, <span class="va">fit</span><span class="op">$</span><span class="va">post_g</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span>, type<span class="op">=</span><span class="st">'n'</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html" class="external-link">range</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_g</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>     xlab <span class="op">=</span> <span class="st">'y'</span>, ylab <span class="op">=</span> <span class="st">'g(y)'</span>, main <span class="op">=</span> <span class="st">"Posterior draws of the transformation"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">temp</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">sapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_g</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">s</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">y0</span>, <span class="va">fit</span><span class="op">$</span><span class="va">post_g</span><span class="op">[</span><span class="va">s</span>,<span class="op">]</span>, col<span class="op">=</span><span class="st">'gray'</span><span class="op">)</span><span class="op">)</span> <span class="co"># posterior draws</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">y0</span>, <span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">colMeans</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_g</span><span class="op">)</span>, lwd <span class="op">=</span> <span class="fl">3</span><span class="op">)</span> <span class="co"># posterior mean</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">dat</span><span class="op">$</span><span class="va">g_true</span>, type<span class="op">=</span><span class="st">'p'</span>, pch<span class="op">=</span><span class="fl">2</span><span class="op">)</span> <span class="co"># true transformation</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/legend.html" class="external-link">legend</a></span><span class="op">(</span><span class="st">'bottomright'</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">'Truth'</span><span class="op">)</span>, pch <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="co"># annotate the true transformation</span></span></span>
<span class="r-plt img"><img src="sblm_hs-3.png" alt="" width="700" height="433"></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Posterior predictive checks on testing data: empirical CDF</span></span></span>
<span class="r-in"><span><span class="va">y0</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unique.html" class="external-link">unique</a></span><span class="op">(</span><span class="va">y_test</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">y0</span>, <span class="va">y0</span>, type<span class="op">=</span><span class="st">'n'</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>     xlab<span class="op">=</span><span class="st">'y'</span>, ylab<span class="op">=</span><span class="st">'F_y'</span>, main <span class="op">=</span> <span class="st">'Posterior predictive ECDF'</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">temp</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">sapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_ypred</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">s</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">y0</span>, <span class="fu"><a href="https://rdrr.io/r/stats/ecdf.html" class="external-link">ecdf</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">post_ypred</span><span class="op">[</span><span class="va">s</span>,<span class="op">]</span><span class="op">)</span><span class="op">(</span><span class="va">y0</span><span class="op">)</span>, <span class="co"># ECDF of posterior predictive draws</span></span></span>
<span class="r-in"><span>        col<span class="op">=</span><span class="st">'gray'</span>, type <span class="op">=</span><span class="st">'s'</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">y0</span>, <span class="fu"><a href="https://rdrr.io/r/stats/ecdf.html" class="external-link">ecdf</a></span><span class="op">(</span><span class="va">y_test</span><span class="op">)</span><span class="op">(</span><span class="va">y0</span><span class="op">)</span>,  <span class="co"># ECDF of testing data</span></span></span>
<span class="r-in"><span>     col<span class="op">=</span><span class="st">'black'</span>, type <span class="op">=</span> <span class="st">'s'</span>, lwd <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="sblm_hs-4.png" alt="" width="700" height="433"></span>
<span class="r-in"><span><span class="co"># }</span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Dan Kowal.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

